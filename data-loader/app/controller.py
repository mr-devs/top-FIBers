"""
Purpose:
    Contains functions that read data files generated by the `repo/scripts/data_processing/`
    scripts and passes them to the database.
    Loaded data is sent to the database tables with different functions for each
    table. See the `database_functions/` directory for details on these functions.

Inputs:
    None

Outputs:
    None

Authors: Pasan Kamburugamuwa & Matthew DeVerna
"""
import datetime
import logging
import os
import re
import traceback

import pandas as pd
from database_functions import reports, fib_indices, posts, reshares

root_dir = "../../data/fib_results/"
FIB_INDICES = "fib_indices"
TOP_SPREADERS = "top_spreader"
N_ROWS = 50

logger = logging.getLogger(__name__)


def add_data(read_dir, platform, selected_month):
    """
    Read preprocessed files and pass data to the database

    Parameters
    -----------
    - read_dir (str): directory to read data from. Combined with `selected_month`
         to create full path to data
    - platform (str): specifies the platform data we are working with
        Options: ["facebook", "twitter"]
    - selected_month (str): The selected month for which we will insert data

    Returns
    -----------
    None
    """
    list_dir = os.listdir(os.path.join(read_dir, selected_month))

    if len(list_dir) > 0:
        logger.info("Found the data directory on that day!")
        file_date = extract_date_convert_datetime(list_dir[0])

        # If the report has already been added to the database for this platform, we skip
        if reports.check_report_already_added(file_date, selected_month, platform):
            report_id = reports.add_reports(file_date, selected_month, platform)

            for file in list_dir:
                try:
                    path_to_data = os.path.join(read_dir, selected_month, file)

                    # This block loads the fib indices file for a given month and
                    # sends its data to the database.
                    # The file loaded is based on the provided `platform`
                    if FIB_INDICES in file:
                        logger.info(
                            f"Loading fib indices file for month: {selected_month}"
                        )
                        df_fib_indices = pd.read_parquet(path_to_data)

                        # The data frame is already sorted in descending order so
                        # taking the top N rows selects the top N FIBers
                        temp_df = df_fib_indices.head(N_ROWS)
                        for index, row in temp_df.iterrows():
                            try:
                                # Send data to fib_indices table
                                fib_indices.add_fib_indices(
                                    row.user_id,
                                    report_id.get("id"),
                                    row.fib_index,
                                    row.total_reshares,
                                    row.username,
                                    platform,
                                )
                            except Exception as err:
                                traceback.print_tb(err.__traceback__)
                                logger.error("Error in adding data to fib indices")

                    # This block loads the top spreaders file for a given month and
                    # sends its data to the database.
                    # The file loaded is based on the provided `platform`
                    elif TOP_SPREADERS in file:
                        logger.info(
                            "Loading top spreader file for the {}", selected_month
                        )
                        df_top_spreaders = pd.read_parquet(path_to_data)
                        for index, row in df_top_spreaders.iterrows():
                            try:
                                # Send data to posts table
                                posts.add_posts(
                                    row.post_id,
                                    row.user_id,
                                    platform,
                                    row.timestamp,
                                    row.post_url,
                                )
                                # Send data to reshares table
                                reshares.add_reshares(
                                    row.post_id,
                                    report_id.get("id"),
                                    platform,
                                    row.num_reshares,
                                )
                            except Exception as err:
                                traceback.print_tb(err.__traceback__)
                                logger.error(
                                    "Error in adding data to post table or reshares table"
                                )
                except FileNotFoundError as e:
                    traceback.print_tb(e.__traceback__)
                    logger.error(f"file {file} does not exist")
        else:
            logger.error(
                "There is already records with the file date. Can not proceed!"
            )
            raise Exception(
                "Already there is a record with file date. Can not proceed!"
            )
    else:
        logger.error("There is no files related to that name!")
        raise Exception("There is no files related to the that name!")


def extract_date_convert_datetime(file_name):
    """
    Extract the date from each file name
    """
    match_str = re.search(r"\d{4}_\d{2}_\d{2}", file_name)
    return datetime.datetime.strptime(match_str.group().replace("_", "-"), "%Y-%m-%d")
