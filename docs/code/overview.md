---
title: "Understanding the project workflow"
last_modified: "2023-05-06"
---
> Last modified: {{ page.last_modified | date: "%Y-%m-%d"}}

There are three general processes that take place for the project to run.

### 1. Getting the data
The first step of the project is retrieving the data that is eventually processed to calculate the [FIB-index](../fib_index.md) values for all users.

Please see the [Data](../data.md) page for all details.

### 2. Preparing the data for process
After data has been retrieved and moved to the `/home/data/apps/topfibers/repo/data/raw` directory, the pipeline works by creating subdirectories full of symbolic links (kept here: `/home/data/apps/topfibers/repo/data/symbolic_links`) that point to the raw files for each platform.

The structure of the `symbolic_links` directory is as follows:
```
├── facebook
│   ├── 2022_01
│   ├── 2022_02
    ...
└── twitter
    ├── 2022_01
    ├── 2022_02
    ...
```
Inside of each `YYYY_MM` subdirectory are symbolic links to for the data used to calculate that month's report. For example, inside of `twitter/2022_01` we have:
```
2022_01
├── 2021-10-01__tweets_w_links.jsonl.gzip -> /home/data/apps/topfibers/repo/data/raw/twitter/2021-10-01__tweets_w_links.jsonl.gzip
├── 2021-11-01__tweets_w_links.jsonl.gzip -> /home/data/apps/topfibers/repo/data/raw/twitter/2021-11-01__tweets_w_links.jsonl.gzip
└── 2021-12-01__tweets_w_links.jsonl.gzip -> /home/data/apps/topfibers/repo/data/raw/twitter/2021-12-01__tweets_w_links.jsonl.gzip
```
This approach allows us to use the `scripts/data_prep/create_data_file_symlinks.py` script to generate unique reports for different time periods (i.e., greater or less than the standard 3 months).
These directories of symbolic links are then provided as input to generate the FIB-index output files.

### 3. Generating FIB-index output file
With the data gathered in the first process, we generate two output files each month.
1. `{YYYY_mm_dd}__fib_indices_{platform}.parquet`: contains all users observed in the three months prior to its calculation (indicated by the prefixed date) ranked by their FIB indices.
    - Contains: ['user_id', 'username', 'fib_index', 'total_reshares']
2. `{YYYY_mm_dd}__top_spreader_posts_{platform}.parquet`: contains data on all POSTS sent by the top 50 superspreaders (according to their FIB indices).
    - Contains: ['user_id', 'post_id', 'num_reshares', 'timestamp', 'post_url']

> Note: Both files are generated by `calc_{platform}_fib_indices.py`
>    - [facebook script](https://github.com/mr-devs/top-FIBers/blob/d94389ec79409eac1154acb1d778eb7c03a751fa/scripts/data_processing/calc_crowdtangle_fib_indices.py)
>    - [twitter script](https://github.com/mr-devs/top-FIBers/blob/d94389ec79409eac1154acb1d778eb7c03a751fa/scripts/data_processing/calc_twitter_fib_indices.py)


### 3. The front end
Once the previous process has completed, we then consume the output of `calc_fib_indices.py` (see [this page for details](./fib_script.md)) and render it nicely on the [OSoMe website](https://osome.iu.edu/).
